name: Daily Open Food Facts Scraper

on:
  schedule:
    - cron: '0 2 * * *'
  workflow_dispatch:

jobs:
  scrape_data:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Change to working directory and run scraper
        run: |
          cd ${{ github.workspace }} # Change current directory to the repo root
          python openfoodfacts_scraper.py # Run the script from the new current directory

      - name: Commit and push updated CSV
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          
          # Add the NEW generated CSV file
          git add openfoodfacts_breakfast_products.csv # <--- CHANGED FROM openfoodfacts_cereals.csv
          
          # Commit only if there are changes
          git diff --quiet --exit-code || git commit -m 'Automated data update from Open Food Facts [skip ci]'
          
          # Push changes
          git push
        working-directory: ${{ github.workspace }} # Ensure git commands run from repo root
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
